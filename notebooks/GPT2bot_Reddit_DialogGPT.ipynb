{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2bot - Reddit feat DialogGPT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12qYj4FafMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "eecf1006-bdbe-43ca-98fd-20ba818124e4"
      },
      "source": [
        "!pip install transformers==2.3.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.14.63)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.16.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.18.0,>=1.17.63 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.17.63)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.63->boto3->transformers==2.3.0) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.63->boto3->transformers==2.3.0) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=603e46f55f92d361723d65cb941a60c7b7b9d25941a02c4eeda14f82987c5c92\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdfxKpnra5Cs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "06dcea62-f8b1-4d1d-c965-b1f1ca67f3d8"
      },
      "source": [
        "!pip install python-telegram-bot --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-telegram-bot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2d/c72fc9a28144277f6170f2fcbfd3bd9427943497522b2689846596eb86cf/python_telegram_bot-12.8-py2.py3-none-any.whl (375kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=5.1 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (5.1.1)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/9c/647e559a6e8be493dc2a7a5d15d26cb501ca60ec299b356f23839a673a83/cryptography-3.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.14.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot) (2.20)\n",
            "Installing collected packages: cryptography, python-telegram-bot\n",
            "Successfully installed cryptography-3.1 python-telegram-bot-12.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY1PPfYRbG0j",
        "colab_type": "text"
      },
      "source": [
        "Run the following cell and restart the runtime if you get any warnings above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7_FYEt-a_GB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "12e0e2ae-e16b-4961-fc39-7fd4a95195bb"
      },
      "source": [
        "!pip install -U ipykernel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: ipykernel in /usr/local/lib/python3.6/dist-packages (5.3.4)\n",
            "Requirement already satisfied, skipping upgrade: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (4.3.3)\n",
            "Requirement already satisfied, skipping upgrade: ipython>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (4.8.0)\n",
            "Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.0.0->ipykernel) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel) (19.0.2)\n",
            "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjvt2nJfZntK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fa434e6b-80d9-4a4f-8242-2db891da1d3d"
      },
      "source": [
        "!git clone https://github.com/polakowo/gpt2bot.git\n",
        "!cp -r gpt2bot/gpt2bot/. . & rm -rf gpt2bot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt2bot'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Total 336 (delta 0), reused 0 (delta 0), pack-reused 336\u001b[K\n",
            "Receiving objects: 100% (336/336), 5.60 MiB | 3.59 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM774HIQbejL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8c4a7fb-f7e0-4015-9524-6e49cd0e9926"
      },
      "source": [
        "!cat chatbot.cfg"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[model]\n",
            "# Path to folder where the model files will be stored.\n",
            "# If path is relative, then the model.py must be called from the same directory.\n",
            "data_folder = models\n",
            "\n",
            "# Size of the GPT-2 model. Could be one of 'small' (117M) or 'medium' (345M)\n",
            "# Select small for CPU or experimentation, and medium for GPU\n",
            "model_size = medium\n",
            "\n",
            "# Dataset name the model was trained on. One of 'multiref' (147M multi-turn dialogue \n",
            "# from Reddit discussion thread) or 'dstc' (DSTC-7 grounded dialogue generation challenge).\n",
            "dataset = multiref\n",
            "\n",
            "# True: load model trained from scratch or False: load model trained from fine-tuning the GPT-2.\n",
            "from_scratch = False\n",
            "\n",
            "# Avoid using CUDA when available.\n",
            "no_cuda = False\n",
            "\n",
            "# Further increases quality by selecting the response that yields lowest backward model loss.\n",
            "# Keep in mind: Uses inference on another medium model and further decreases bot's response time.\n",
            "# You should set num_samples > 1 for this to work\n",
            "use_mmi = False\n",
            "\n",
            "[decoder]\n",
            "# Seed for random number generators, fix seed to reproduce results.\n",
            "# By default there is no seed and each turn should be unique.\n",
            "seed\n",
            "\n",
            "# Float value controlling randomness in boltzmann\n",
            "# distribution. Lower temperature results in less random completions. As the\n",
            "# temperature approaches zero, the model will become deterministic and\n",
            "# repetitive. Higher temperature results in more random completions.\n",
            "temperature = 0.7\n",
            "\n",
            "# Integer value controlling diversity. 1 means only 1 word is\n",
            "# considered for each step (token), resulting in deterministic completions,\n",
            "# while 40 means 40 words are considered at each step. 0 (default) is a\n",
            "# special setting meaning no restrictions. 40 generally is a good value.\n",
            "top_k = 40\n",
            "\n",
            "# Like top_k, top_p is a constraint on the craziness of the output\n",
            "top_p = 0\n",
            "\n",
            "# The maximal number of tokens to be returned, inclusive of punctuations etc.\n",
            "# It will automatically stop if the end-of-sequence token was found earlier.\n",
            "# Usually, only in rare cases generation will go beyond 64 tokens.\n",
            "max_length = 128\n",
            "\n",
            "# Number of samples to generate.\n",
            "# You will have to implement a strategy to choose one message from generated list.\n",
            "# For example, you can choose the most dissimilar message, or the lengthiest one.\n",
            "# But keep in mind: the higher, the slower the generation.\n",
            "num_samples = 1\n",
            "\n",
            "# The number of turns (turn = answer and response) the model should consider. \n",
            "# Set to 0 to focus on the last message. Set to -1 for unlimited context length.\n",
            "max_turns_history = 2\n",
            "\n",
            "[chatbot]\n",
            "\n",
            "# Your Telegram token. See https://core.telegram.org/bots\n",
            "telegram_token = YOUR_TOKEN_HERE\n",
            "\n",
            "# Your GIPHY API token. See \n",
            "giphy_token = YOUR_TOKEN_HERE\n",
            "\n",
            "# Value from 0-10 which makes results weirder as you go up the scale.\n",
            "giphy_weirdness = 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXsTgp27q0Rx",
        "colab_type": "text"
      },
      "source": [
        "Change the config file how you like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4_7cTmaavIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser(allow_no_value=True)\n",
        "config.read('chatbot.cfg')\n",
        "config.set('chatbot', 'telegram_token', '1368252640:AAGHxUTVDuu_Lqy4BYh6F23kdKnkgFrK0-k')\n",
        "\n",
        "with open('my_chatbot.cfg', 'w') as f:\n",
        "    config.write(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1706pocb5eZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "cadf7215-c97e-4477-94ef-5ab2f1037432"
      },
      "source": [
        "!cat my_chatbot.cfg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[model]\n",
            "data_folder = models\n",
            "model_size = medium\n",
            "dataset = multiref\n",
            "from_scratch = False\n",
            "no_cuda = False\n",
            "use_mmi = False\n",
            "\n",
            "[decoder]\n",
            "seed\n",
            "temperature = 0.7\n",
            "top_k = 40\n",
            "top_p = 0\n",
            "max_length = 128\n",
            "num_samples = 1\n",
            "max_turns_history = 2\n",
            "\n",
            "[chatbot]\n",
            "telegram_token = 1368252640:AAGHxUTVDuu_Lqy4BYh6F23kdKnkgFrK0-k\n",
            "giphy_token = YOUR_TOKEN_HERE\n",
            "giphy_weirdness = 5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5xTyqGdnh1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7871c159-10cb-4125-ef22-bae6edfdd60f"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep 22 12:42:56 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "638dKOn7q8Bx",
        "colab_type": "text"
      },
      "source": [
        "Run the interactive chatbot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgwI4QdUcP6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "999040b6-1a7d-473c-9efb-34751a83ecf0"
      },
      "source": [
        "!python interactive_bot.py --config my_chatbot.cfg"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-22 12:43:05.898008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/content/decoder.py:118: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
            "  assert(num_samples > 1, \"MMI requires num_samples > 1\")\n",
            "2020-09-22 12:43:07,832 - model - INFO - Downloading model files to medium_multiref_ft...\n",
            "100% 293/293 [00:00<00:00, 207905.78B/s]\n",
            "100% 1042301/1042301 [00:01<00:00, 785082.09B/s]\n",
            "100% 456318/456318 [00:00<00:00, 532393.47B/s]\n",
            "100% 862954531/862954531 [01:13<00:00, 11668538.20B/s]\n",
            "2020-09-22 12:44:26,724 - model - INFO - Loading model from medium_multiref_ft...\n",
            "2020-09-22 12:44:55,148 - __main__ - INFO - Running the chatbot...\n",
            "Bot >>> Just start texting me. If I'm getting annoying, type \"Bye\". To quit the chat type \"Quit\".\n",
            "User >>> what is arxiv ?\n",
            "Bot >>> A repository of research.\n",
            "User >>> who is margherita pagani ?\n",
            "Bot >>> You know, she's a lady.\n",
            "User >>> Bye\n",
            "Bot >>> Bye\n",
            "User >>> Quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS4rSjXUq9m-",
        "colab_type": "text"
      },
      "source": [
        "Run the Telegram bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmnarYPGTJQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = configparser.ConfigParser(allow_no_value=True)\n",
        "config.read(f'chatbot.cfg')\n",
        "config.set('chatbot', 'telegram_token', '1368252640:AAGHxUTVDuu_Lqy4BYh6F23kdKnkgFrK0-k')\n",
        "config.set('chatbot', 'giphy_token', '*YOUR_TOKEN_HERE*')\n",
        "\n",
        "with open(f'my_chatbot.cfg', 'w') as f:\n",
        "    config.write(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de-g5_AUTQZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "da112f43-fd99-4ce0-c4a4-34ccc3508df9"
      },
      "source": [
        "!cat my_chatbot.cfg"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[model]\n",
            "data_folder = models\n",
            "model_size = medium\n",
            "dataset = multiref\n",
            "from_scratch = False\n",
            "no_cuda = False\n",
            "use_mmi = False\n",
            "\n",
            "[decoder]\n",
            "seed\n",
            "temperature = 0.7\n",
            "top_k = 40\n",
            "top_p = 0\n",
            "max_length = 128\n",
            "num_samples = 1\n",
            "max_turns_history = 2\n",
            "\n",
            "[chatbot]\n",
            "telegram_token = 1368252640:AAGHxUTVDuu_Lqy4BYh6F23kdKnkgFrK0-k\n",
            "giphy_token = *YOUR_TOKEN_HERE*\n",
            "giphy_weirdness = 5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AcaOYfkh3dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "83056afe-a718-497d-c983-6522ed3c4634"
      },
      "source": [
        "!python telegram_bot.py --config my_chatbot.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-22 12:49:18.932200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-09-22 12:49:20,930 - model - INFO - Downloading model files to medium_multiref_ft...\n",
            "2020-09-22 12:49:20,930 - model - INFO - Loading model from medium_multiref_ft...\n",
            "2020-09-22 12:49:40,062 - __main__ - INFO - Initializing the bot...\n",
            "2020-09-22 12:49:40,063 - __main__ - INFO - Running the chatbot...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBSolNDhsqrX",
        "colab_type": "text"
      },
      "source": [
        "Go to your bot's Telegram channel, type /start and start conversation with the bot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ULFoe0ljNbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}